{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3898b5dc-caae-43e6-9071-44f3a4d30066",
   "metadata": {},
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0fb705f-351d-4e84-8806-939c6ab5203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # routine analysis with dataframes\n",
    "import numpy as np # routine array analysis\n",
    "import pickle # reading in pickle files (PCA morphospace file)\n",
    "from scipy.spatial import ConvexHull # for calculating convex hull of morphospace\n",
    "from scipy.spatial import Delaunay # for delauney triangulation functions\n",
    "from scipy.stats import dirichlet # for sampling simplices in the morphospace\n",
    "from numpy.linalg import det # for sampling simplices in the morphospace\n",
    "import math # for math functions\n",
    "import os # for directory functions\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "from shapely.geometry import Polygon, Point # for point and polygon operations\n",
    "from shapely.ops import nearest_points # for calculating leaf curvature\n",
    "import trimesh # for working with triangular meshes and ray casting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca66a6-dd7c-475a-8341-f2df6e755798",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1dd6a41-52fd-4944-9c49-4146f6eb335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(keys, values, path):\n",
    "\n",
    "    \"\"\"\n",
    "    Given lists of parameter variable names and values, saves as csv file to desired path\n",
    "    \n",
    "    Inputs \n",
    "    keys: a list of keys, parameter names\n",
    "    values: a list of values, parameter values\n",
    "    path: a filename path to save the param values as .csv file\n",
    "\n",
    "    Outputs:\n",
    "    No return, saves the csv to the desired path\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert values into lists\n",
    "    list_vals = [[x] for x in values]\n",
    "    \n",
    "    # convert parameter names and values into dictionary\n",
    "    data = dict(zip(keys, list_vals))\n",
    "    \n",
    "    # convert dict into df\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    # save param values\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "def set_params(path):\n",
    "\n",
    "    \"\"\"\n",
    "    Given a path, read in a csv file with parameter variable names and values\n",
    "    \n",
    "    Inputs \n",
    "    path: a filename path to read in a csv \n",
    "\n",
    "    Outputs:\n",
    "    Sets global variables and values from the csv file\n",
    "    Returns a dictionary of parameter names and values\n",
    "    \"\"\"\n",
    "    \n",
    "    # read in param values from csv\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # create variables for parameters\n",
    "    for column in df.columns:\n",
    "        globals()[column] = df[column].item()\n",
    "\n",
    "    # create a dictionary of parameter variables to return\n",
    "    param_var_list = [\n",
    "        \"parameter_name\", \n",
    "        \"morphospace_file\", \n",
    "        \"PC_val_file\",\n",
    "        \"PCa\", \n",
    "        \"PCb\",\n",
    "        \"grid_density\",\n",
    "        \"low_lf_num\",\n",
    "        \"high_lf_num\",\n",
    "        \"low_juv_len\",\n",
    "        \"high_juv_len\",\n",
    "        \"low_adult_len\",\n",
    "        \"high_adult_len\",\n",
    "        \"lf_curve\",\n",
    "        \"lf_curl\",\n",
    "        \"max_down_curl\",\n",
    "        \"max_up_curl\",\n",
    "        \"ang_min_limit\",\n",
    "        \"ang_max_limit\",\n",
    "        \"phyllo_option\"]\n",
    "\n",
    "    param_val_list = [\n",
    "        parameter_name, \n",
    "        morphospace_file, \n",
    "        PC_val_file,\n",
    "        PCa, \n",
    "        PCb,\n",
    "        grid_density,\n",
    "        low_lf_num,\n",
    "        high_lf_num,\n",
    "        low_juv_len,\n",
    "        high_juv_len,\n",
    "        low_adult_len,\n",
    "        high_adult_len,\n",
    "        lf_curve,\n",
    "        lf_curl,\n",
    "        max_down_curl,\n",
    "        max_up_curl,\n",
    "        ang_min_limit,\n",
    "        ang_max_limit,\n",
    "        phyllo_option]\n",
    "    \n",
    "    # convert parameter names and values into dictionary\n",
    "    param_var_dict = dict(zip(param_var_list, param_val_list))\n",
    "\n",
    "    return param_var_dict\n",
    "\n",
    "def dist_in_hull(points, n):\n",
    "\n",
    "    \"\"\"\n",
    "    From: https://stackoverflow.com/questions/59073952/how-to-get-uniformly-distributed-points-in-convex-hull\n",
    "    Accessed 11 February 2024\n",
    "    \n",
    "    Given a set of points, find delauney simplices of hull and randomly sample n points within\n",
    "\n",
    "    Inputs:\n",
    "    points: an array of point values, any dimensions\n",
    "    n: the number of points to sample within the convex hull\n",
    "\n",
    "    Outputs\n",
    "    coordinates of randomly sampled points (array)\n",
    "    \"\"\"\n",
    "    \n",
    "    dims = points.shape[-1]\n",
    "    hull = points[ConvexHull(points).vertices]\n",
    "    deln = hull[Delaunay(hull).simplices]\n",
    "\n",
    "    vols = np.abs(det(deln[:, :dims, :] - deln[:, dims:, :])) / math.factorial(dims)    \n",
    "    sample = np.random.choice(len(vols), size = n, p = vols / vols.sum())\n",
    "\n",
    "    return np.einsum('ijk, ij -> ik', deln[sample], dirichlet.rvs([1]*(dims + 1), size = n))\n",
    "\n",
    "def select_leaf_number(low_lf_num, high_lf_num):\n",
    "    \"\"\"\n",
    "    Given low and high leaf number values, uniformly sample a leaf number for the plant\n",
    "    \n",
    "    Inputs\n",
    "    low_lf_num: integer value of lowest possible leaf number (inclusive)\n",
    "    high_lf_num: integer value of highest possible leaf number (not included)\n",
    "\n",
    "    Ouputs\n",
    "    n: the selected leaf number uniformly sampled from provided range\n",
    "    \"\"\"\n",
    "\n",
    "    return np.random.randint(low_lf_num, high_lf_num) \n",
    "\n",
    "def select_phyllotaxy_angle(phyllo_option):\n",
    "    \"\"\"\n",
    "    Given a phyllotaxy angle option value (see below) set phyllotaxy angle\n",
    "\n",
    "    Inputs\n",
    "    phyllo_option: integer value selecting phyllotaxy option\n",
    "\n",
    "    Outputs\n",
    "    phyllo_ang: float value of calculated phyllotaxy angle\n",
    "    \"\"\"\n",
    "\n",
    "    # 0 = [-137.5077640500378546463487,137.5077640500378546463487]\n",
    "    # 1 = [-137.5077640500378546463487,137.5077640500378546463487,90,180]\n",
    "    # 2 = [-137.5077640500378546463487,137.5077640500378546463487,90,180,<random -360 to +360>]\n",
    "    # 3 = [<random -360 to +360>]\n",
    "\n",
    "    if phyllo_option==0:\n",
    "        phyllo_ang=np.random.choice(np.array([-137.5077640500378546463487,137.5077640500378546463487]))\n",
    "    elif phyllo_option==1:\n",
    "        phyllo_ang=np.random.choice(np.array([-137.5077640500378546463487,137.5077640500378546463487,90,180]))\n",
    "    elif phyllo_option==2:\n",
    "        phyllo_ang=np.random.choice(np.array([-137.5077640500378546463487,137.5077640500378546463487,90,180,np.random.uniform(-360,360)]))\n",
    "    else:\n",
    "        phyllo_ang=np.random.uniform(-360,360)\n",
    "\n",
    "    return phyllo_ang\n",
    "\n",
    "def select_leaf_lengths(low_juv_len, high_juv_len, low_adult_len, high_adult_len):\n",
    "    \"\"\"\n",
    "    Given relative leaf lengths of start (juvenile) and end (adult) of leaf series, set relative leaf lengths\n",
    "\n",
    "    Inputs\n",
    "    low_juv_len: low limit juvenile leaf length (relative to 1)\n",
    "    high_juv_len: high limit juvenile leaf length (relative to 1)\n",
    "    low_adult_len: low limit adult leaf length (relative to 1)\n",
    "    high_adult_len: high limit adult leaf length (relative to 1)\n",
    "\n",
    "    Outputs\n",
    "    juv_len: the relative length to 1 of juvenile leaf\n",
    "    adult_len: the relative length to 1 of the adult leaf\n",
    "    node_max: the node in the leaf series of the max leaf height (from 0 to 1)\n",
    "    \"\"\"\n",
    "    # select relative height of first leaf in series\n",
    "    juv_len = np.random.uniform(low_juv_len, high_juv_len) \n",
    "    \n",
    "    # set node position of max leaf height of 1 (0 to 1)\n",
    "    node_max = np.random.uniform(0.1, 0.9) # a little bit in from 0 and 1 at 0.1 to 0.9\n",
    "    \n",
    "    # set the relative height of last leaf in series\n",
    "    adult_len = np.random.uniform(low_adult_len, high_adult_len) \n",
    "\n",
    "    return juv_len, adult_len, node_max\n",
    "\n",
    "def select_leaf_surface_variables(lf_curve, lf_curl, max_down_curl, max_up_curl):\n",
    "    \"\"\"\n",
    "    Given curvature and curling scaling values and positioning of curling, return leaf surface (z axis) values\n",
    "\n",
    "    Inputs:\n",
    "    lf_curve: scaling factor for the amount of leaf curvature (relative to leaf margins)\n",
    "    lf_curl: scaling factor for the amount of leaf curling (from base to tip)\n",
    "    max_down_curl: a 0 to 1 value of maximum downward curl\n",
    "    max_up_curl: a 0 to 1 value of maximum upward curl\n",
    "\n",
    "    Outputs:\n",
    "    leaf_curve: the leaf curvature scaling amount\n",
    "    leaf_curl: the leaf curling scaling amount\n",
    "    leaf_tip: the leaf curling value at the tip of the leaf\n",
    "    leaf_mid: the leaf curling value at the mid point of the leaf length\n",
    "    \"\"\"\n",
    "    # calculate the scaling factor for leaf curvature and leaf curl\n",
    "    leaf_curve = np.random.uniform(0,lf_curve) \n",
    "    leaf_curl = np.random.uniform(0,lf_curl) \n",
    "    \n",
    "    # calculate leaf curl amount (z value)\n",
    "    leaf_tip = np.random.uniform(max_down_curl,max_up_curl) \n",
    "    \n",
    "    # set middle of leaf curl (also z value, but curl at mid point of length)\n",
    "    leaf_mid = np.random.uniform(0,leaf_tip) \n",
    "\n",
    "    return leaf_curve, leaf_curl, leaf_tip, leaf_mid\n",
    "\n",
    "def select_leaf_elevation_angles(ang_min_limit, ang_max_limit):\n",
    "    \"\"\"\n",
    "    Given the minimum and maximum leaf angle limits, calculate the leaf elevation limits\n",
    "\n",
    "    Inputs\n",
    "    ang_min_limit: the minimum angle limit (in the context of 0 to the limit)\n",
    "    ang_max_limit: the maximum angle limit (in the context of the selected min angle to the max limit)\n",
    "\n",
    "    Outputs\n",
    "    angle_min: the selected minimum angle value\n",
    "    angle_max: the selected maximum angle value\n",
    "    \"\"\"\n",
    "    # calculate elevation angles\n",
    "    angle_min = np.random.uniform(0,ang_min_limit) # get the minimum angle\n",
    "    angle_max = np.random.uniform(angle_min,ang_max_limit) # get the maximum angle\\\n",
    "\n",
    "    return angle_min, angle_max\n",
    "\n",
    "def select_morphospace_points(morphospace_file, PC_val_file, PCa, PCb):\n",
    "    \"\"\"\n",
    "    Given a morphospace and PC values select morphospace points to generate a leaf shape series\n",
    "\n",
    "    Inputs\n",
    "    morphospace_file: path to a morphospace file (.pkl)\n",
    "    PC_val_file: path to PC value file (.npy)\n",
    "    PCa: the first PC axis to consider (index starts at 0)\n",
    "    PCb: the second PC axis to consider (index starts at 0)\n",
    "\n",
    "    Outputs:\n",
    "    start_x: the x value (PCa) of the leaf series start\n",
    "    start_y: the y value (PCb) of the leaf series start\n",
    "    end_x: the x value (PCa) of the leaf series end\n",
    "    end_y: the y value (PCb) of the leaf series end\n",
    "    \"\"\"\n",
    "    # find the two points in PCA space to make the leaf series\n",
    "    # Load PCA model\n",
    "    with open(morphospace_file, 'rb') as file:\n",
    "        pca = pickle.load(file)\n",
    "    # Load in PC values\n",
    "    PCs = np.load(PC_val_file)\n",
    "    \n",
    "    # retrieve just the desired two PCs\n",
    "    just_PCs = PCs[:,[PCa,PCb]]\n",
    "    # create the convex hull\n",
    "    hull = ConvexHull(just_PCs)\n",
    "    # retreieve hull points\n",
    "    hull_points = just_PCs[hull.vertices]\n",
    "    # find two random points in 2D convex hull\n",
    "    # these are the terminal points of the line\n",
    "    term_pts = dist_in_hull(hull_points,2)\n",
    "    # these are the values of the coordinate points\n",
    "    start_x = term_pts[0][0]\n",
    "    start_y = term_pts[0][1]\n",
    "    end_x = term_pts[1][0]\n",
    "    end_y = term_pts[1][0]\n",
    "\n",
    "    return start_x, start_y, end_x, end_y\n",
    "\n",
    "def save_model_values(param_var_dict, model_results_path, n_models):\n",
    "    \"\"\"\n",
    "    Given parameter values, generate and save values to create models\n",
    "\n",
    "    Inputs\n",
    "    param_var_dict: a dictionary of parameter variables and values\n",
    "    model_results_path: path to create a folder to save model values\n",
    "    n_models: the desired number of model values to save\n",
    "\n",
    "    Outputs\n",
    "    No return, but save desirved number of model values in specified folder as csv files\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(model_results_path): # check if the folder exists\n",
    "        # create the folder if it doesn't exist\n",
    "        os.makedirs(model_results_path)\n",
    "\n",
    "    # unpack parameter variable list\n",
    "    parameter_name=param_var_dict[\"parameter_name\"]\n",
    "    morphospace_file=param_var_dict[\"morphospace_file\"]\n",
    "    PC_val_file=param_var_dict[\"PC_val_file\"]\n",
    "    PCa=param_var_dict[\"PCa\"]\n",
    "    PCb=param_var_dict[\"PCb\"]\n",
    "    grid_density=param_var_dict[\"grid_density\"]\n",
    "    low_lf_num=param_var_dict[\"low_lf_num\"]\n",
    "    high_lf_num=param_var_dict[\"high_lf_num\"]\n",
    "    low_juv_len=param_var_dict[\"low_juv_len\"]\n",
    "    high_juv_len=param_var_dict[\"high_juv_len\"]\n",
    "    low_adult_len=param_var_dict[\"low_adult_len\"]\n",
    "    high_adult_len=param_var_dict[\"high_adult_len\"]\n",
    "    lf_curve=param_var_dict[\"lf_curve\"]\n",
    "    lf_curl=param_var_dict[\"lf_curl\"]\n",
    "    max_down_curl=param_var_dict[\"max_down_curl\"]\n",
    "    max_up_curl=param_var_dict[\"max_up_curl\"]\n",
    "    ang_min_limit=param_var_dict[\"ang_min_limit\"]\n",
    "    ang_max_limit=param_var_dict[\"ang_max_limit\"]\n",
    "    phyllo_option=param_var_dict[\"phyllo_option\"]\n",
    "\n",
    "    for m in range(n_models):\n",
    "    \n",
    "        # select number of leaves\n",
    "        n = select_leaf_number(low_lf_num, high_lf_num)\n",
    "    \n",
    "        # select phyllotactic angle\n",
    "        phyllo_ang = select_phyllotaxy_angle(phyllo_option)\n",
    "    \n",
    "        # select leaf lengths\n",
    "        juv_len, adult_len, node_max = select_leaf_lengths(low_juv_len, high_juv_len, low_adult_len, high_adult_len)\n",
    "    \n",
    "        # select leaf surface variables\n",
    "        leaf_curve, leaf_curl, leaf_tip, leaf_mid = select_leaf_surface_variables(lf_curve, lf_curl, max_down_curl, max_up_curl)\n",
    "    \n",
    "        # select leaf elevation angles\n",
    "        angle_min, angle_max = select_leaf_elevation_angles(ang_min_limit, ang_max_limit)\n",
    "    \n",
    "        # select morphospace points\n",
    "        start_x, start_y, end_x, end_y = select_morphospace_points(morphospace_file, PC_val_file, PCa, PCb)\n",
    "    \n",
    "        model_var_list = [\n",
    "            \"n\",\n",
    "            \"phyllo_ang\",\n",
    "            \"juv_len\",\n",
    "            \"adult_len\",\n",
    "            \"node_max\",\n",
    "            \"leaf_curve\",\n",
    "            \"leaf_curl\",\n",
    "            \"leaf_tip\",\n",
    "            \"leaf_mid\",\n",
    "            \"angle_min\",\n",
    "            \"angle_max\",\n",
    "            \"start_x\",\n",
    "            \"start_y\",\n",
    "            \"end_x\",\n",
    "            \"end_y\"\n",
    "           ]\n",
    "    \n",
    "        model_val_list = [\n",
    "            n,\n",
    "            phyllo_ang,\n",
    "            juv_len,\n",
    "            adult_len,\n",
    "            node_max,\n",
    "            leaf_curve,\n",
    "            leaf_curl,\n",
    "            leaf_tip,\n",
    "            leaf_mid,\n",
    "            angle_min,\n",
    "            angle_max,\n",
    "            start_x,\n",
    "            start_y,\n",
    "            end_x,\n",
    "            end_y\n",
    "            ]\n",
    "\n",
    "        # convert values into lists\n",
    "        model_val_list = [[x] for x in model_val_list]\n",
    "    \n",
    "        # convert parameter names and values into dictionary\n",
    "        model_var_dict = dict(zip(model_var_list, model_val_list))\n",
    "\n",
    "        # convert dict into df\n",
    "        df = pd.DataFrame.from_dict(model_var_dict)\n",
    "        \n",
    "        # save param values\n",
    "        df.to_csv(\"./\" + model_results_path + \"/m\" + str(m) + \"_\" + parameter_name + \".csv\", index=False)\n",
    "\n",
    "def set_model_values(path):\n",
    "    \"\"\"\n",
    "    Given a model values file, read in and set model values\n",
    "\n",
    "    Inputs\n",
    "    path: a path to a model value .csv file\n",
    "\n",
    "    Outputs\n",
    "    model_var_dict: a dictionary of model values\n",
    "    The function sets global values for model variables\n",
    "    \"\"\"\n",
    "\n",
    "    # read in model values from csv\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # create variables for parameters\n",
    "    for column in df.columns:\n",
    "        globals()[column] = df[column].item()\n",
    "    \n",
    "    # create a dictionary of model values to return\n",
    "    model_var_list = [\n",
    "        \"n\",\n",
    "        \"phyllo_ang\",\n",
    "        \"juv_len\",\n",
    "        \"adult_len\",\n",
    "        \"node_max\",\n",
    "        \"leaf_curve\",\n",
    "        \"leaf_curl\",\n",
    "        \"leaf_tip\",\n",
    "        \"leaf_mid\",\n",
    "        \"angle_min\",\n",
    "        \"angle_max\",\n",
    "        \"start_x\",\n",
    "        \"start_y\",\n",
    "        \"end_x\",\n",
    "        \"end_y\"\n",
    "       ]\n",
    "    \n",
    "    model_val_list = [\n",
    "        n,\n",
    "        phyllo_ang,\n",
    "        juv_len,\n",
    "        adult_len,\n",
    "        node_max,\n",
    "        leaf_curve,\n",
    "        leaf_curl,\n",
    "        leaf_tip,\n",
    "        leaf_mid,\n",
    "        angle_min,\n",
    "        angle_max,\n",
    "        start_x,\n",
    "        start_y,\n",
    "        end_x,\n",
    "        end_y\n",
    "        ]\n",
    "    \n",
    "    # convert model names and values into dictionary\n",
    "    model_var_dict = dict(zip(model_var_list, model_val_list))\n",
    "\n",
    "    return model_var_dict\n",
    "\n",
    "def read_in_morphospace(morphospace_file, PC_val_file):\n",
    "    \"\"\"\n",
    "    Given paths to morphospace and PC value files, read in the data\n",
    "\n",
    "    Inputs\n",
    "    morphospace_file: path to a pickle file (.pkl) of the PCA model (the morphospace)\n",
    "    PC_val_file: path to a numpy file (.npy) of an array of the PC values\n",
    "\n",
    "    Outputs\n",
    "    pca: the PCA model of the morphospace\n",
    "    PCs: an array of PC values\n",
    "    \"\"\"\n",
    "    pca = pickle.load(open(morphospace_file,'rb')) \n",
    "    PCs = np.load(PC_val_file)\n",
    "\n",
    "    return pca, PCs\n",
    "\n",
    "def generate_leaf_series(n,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca):\n",
    "    \"\"\"\n",
    "    Given a morphospace and start and end point, generate a leaf series for n leaves between the points\n",
    "\n",
    "    Inputs\n",
    "    n: the number of leaves in the series to generate\n",
    "    start_x, start_y: x,y coords of the start point in PCA space\n",
    "    end_x, end_y: x,y coords of the end point in PCA space\n",
    "    PCs: an array of PC values\n",
    "    PCa: index position of the \"x axis\" PC to use (index starts at 0)\n",
    "    PCb: index position of the \"y axis\" PC to use (index starts at 0)\n",
    "    pca: a predefined morphospace PCA model\n",
    "\n",
    "    Ouputs\n",
    "    leaf_series: a 3D array of the eigenleaves in the series\n",
    "    \"\"\"\n",
    "\n",
    "    # Create an array of evenly spaced values from 0 to 1\n",
    "    t_values = np.linspace(0, 1, n)\n",
    "\n",
    "    # define start and end points of leaf series\n",
    "    start_point = np.array([start_x, start_y])\n",
    "    end_point = np.array([end_x, end_y])\n",
    "    \n",
    "    # Calculate the points using linear interpolation\n",
    "    points = np.array([start_point + t * (end_point - start_point) for t in t_values])\n",
    "    \n",
    "    # calculate eigen leaves\n",
    "    eigen_arr = np.zeros((len(points),np.shape(PCs)[1])) # create an array for eigenleaf, length of number of PCs\n",
    "    eigen_arr[:,PCa] = points[:,0] # set the PCa values\n",
    "    eigen_arr[:,PCb] = points[:,1] # set the PCb values\n",
    "    \n",
    "    # calculate the inverse eigenleaf\n",
    "    inv_leaf = pca.inverse_transform(eigen_arr)\n",
    "    inv_x = inv_leaf[:,0::2] # select just inverse x vals\n",
    "    inv_y = inv_leaf[:,1::2] # select just inverse y vals\n",
    "    \n",
    "    # create an array of the leaf series\n",
    "    leaf_series = np.stack((inv_x, inv_y), axis=1)\n",
    "    leaf_series = np.swapaxes(leaf_series, 1,2)\n",
    "\n",
    "    return leaf_series\n",
    "\n",
    "def is_self_intersecting(polygon_coordinates):\n",
    "    \"\"\"\n",
    "    Checks if a polygon is self-intersecting.\n",
    "\n",
    "    Args:\n",
    "        polygon_coordinates: A list of (x, y) tuples representing the polygon's vertices.\n",
    "\n",
    "    Returns:\n",
    "        True if the polygon is self-intersecting, False otherwise.\n",
    "    \"\"\"\n",
    "    polygon = Polygon(polygon_coordinates)\n",
    "    return not polygon.is_simple\n",
    "\n",
    "def any_leaf_self_intersecting(leaf_series):\n",
    "    \"\"\"\n",
    "    Given an array representing leaves in the leaf series, determine if any are self-intersecting polygons\n",
    "\n",
    "    Inputs\n",
    "    leaf_series: a 3D array of 2D leaf shapes in the leaf series\n",
    "\n",
    "    Outputs\n",
    "    True/False: is any leaf shape in the series self-intersecting?\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(len(leaf_series)):\n",
    "        if is_self_intersecting(leaf_series[i]):\n",
    "            return True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return False\n",
    "\n",
    "def translate_base_to_origin(leaf_series):\n",
    "    \"\"\"\n",
    "    Given a leaf series, return each leaf in the series translated with its base to the origin\n",
    "\n",
    "    Inputs\n",
    "    leaf_series: a 3D array of a leaf series\n",
    "\n",
    "    Outputs\n",
    "    trans_lfs: 1 3D array of the leaf series with bases translated to the origin\n",
    "    \"\"\"\n",
    "\n",
    "    trans_lfs = np.zeros(np.shape(leaf_series))\n",
    "    \n",
    "    for i in range(len(leaf_series)):\n",
    "        start_pt = leaf_series[i,0,:] # leaf start\n",
    "        end_pt = leaf_series[i,-1,:] # leaf end\n",
    "        base_pt = np.mean((start_pt, end_pt), axis=0) # base point of leaf\n",
    "        trans_lf = leaf_series[i,:,:] - base_pt # translated lf\n",
    "        trans_lfs[i,:,:] = trans_lf # save translated lf\n",
    "\n",
    "    return trans_lfs\n",
    "\n",
    "def scale_leaf_series(node_max, juv_len, adult_len, trans_lfs, n):\n",
    "    \"\"\"\n",
    "    Given 1) a leaf series 2) with each leaf base translated to the origin, use a funciton to calculate leaf lengths across the series\n",
    "\n",
    "    Inputs\n",
    "    node_max: for nodes across the leaf series 0 to 1, the value where the leaf length is the maximum value\n",
    "    juv_len, adult_len: the relative lengths of the leaves (0 to 1) for the first (juvenile) and last (adult) node respectively\n",
    "    trans_lfs: a 3D array of leaf shapes for a leaf series to calculate lengths for each leaf for\n",
    "\n",
    "    Outputs\n",
    "    scaled_lfs: a 3D array for a leaf series where the length of each leaf has been scaled appropriately\n",
    "    \"\"\"\n",
    "    \n",
    "    # find relative lengths for each leaf (to 1)\n",
    "    coeffs = np.polyfit(x=[0,node_max,1], y=[juv_len,1,adult_len], deg=2) # calculate coefficients\n",
    "    func = np.poly1d(coeffs) # calculate 2D polynomial function\n",
    "    lf_lens = func(np.linspace(0,1,n)) # calculate leaf lengths relative to 1\n",
    "    \n",
    "    scaled_lfs = np.zeros(np.shape(trans_lfs))\n",
    "    for i in range(len(scaled_lfs)): # for each leaf in the series\n",
    "        scale_len_lf = trans_lfs[i,:,:]/np.max(trans_lfs[i,:,1]) # scale leaf len to 1\n",
    "        scale_len_lf = scale_len_lf*lf_lens[i] # scale leaf to desired length\n",
    "        scaled_lfs[i,:,:] = scale_len_lf # save scaled length leaf\n",
    "\n",
    "    return scaled_lfs\n",
    "\n",
    "def save_leaf_series(file,leaf_series_path,n_save,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca,node_max,juv_len,adult_len):\n",
    "    \"\"\"\n",
    "    Save an array of leaf shapes across the series with the same number of leaves for comparison\n",
    "\n",
    "    Inputs\n",
    "    In addition to parameters needed for the previous functions:\n",
    "    file: the current model_values file name, to retrieve the number ID of the current model to save the leaf series\n",
    "    leaf_series_path: a folder name to save the leaf series files as arrays\n",
    "    n_save: this is different from n, the number of leaves in the series. n_save is the standard number of leaves to save for the leaf series\n",
    "\n",
    "    Outputs\n",
    "    No return, saves the leaf series array as a .npy file to the specified folder path\n",
    "    \"\"\"\n",
    "\n",
    "    # generate a leaf series to save for the desired number of leaves\n",
    "    nsave_lf_series = generate_leaf_series(n_save,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca)\n",
    "    # translate each leaf base to the origin\n",
    "    trans_nsave_lf_series = translate_base_to_origin(nsave_lf_series)\n",
    "    # scale leaves across the series to the appropriate length\n",
    "    scale_nsave_lf_series = scale_leaf_series(node_max, juv_len, adult_len, trans_nsave_lf_series, n=n_save)\n",
    "\n",
    "    if not os.path.exists(leaf_series_path): # check if the folder exists\n",
    "        # create the folder if it doesn't exist\n",
    "        os.makedirs(leaf_series_path)\n",
    "\n",
    "    # save the leaf series \n",
    "    np.save(leaf_series_path + \"/\" + \"l\" + file[1:-4], scale_nsave_lf_series)\n",
    "\n",
    "def hexagonal_points_for_n(vertices_2d: np.ndarray, target_n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Given a 2D polygon, provide hexagonally spaced points of the approximate target number\n",
    "\n",
    "    Inputs\n",
    "    vertices: a 2D array of the polygon boundaries\n",
    "    grid_density: the approximate number of points within the polygon\n",
    "\n",
    "    Outputs\n",
    "    hex_pts: a 2D array of hexagonal grid points\n",
    "    \"\"\"\n",
    "\n",
    "    poly = Polygon(vertices_2d)\n",
    "    area = poly.area\n",
    "\n",
    "    # Estimate point density of hex grid: ~1 point per (sqrt(3)/2)*spacing^2 area\n",
    "    hex_cell_area = area / target_n\n",
    "    spacing = np.sqrt((2 * hex_cell_area) / np.sqrt(3))\n",
    "\n",
    "    minx, miny, maxx, maxy = poly.bounds\n",
    "    dx = spacing\n",
    "    dy = spacing * np.sqrt(3) / 2\n",
    "\n",
    "    points = []\n",
    "    j = 0\n",
    "    y = miny\n",
    "    while y <= maxy:\n",
    "        x_offset = (dx / 2) if (j % 2 == 1) else 0\n",
    "        x = minx + x_offset\n",
    "        while x <= maxx:\n",
    "            p = Point(x, y)\n",
    "            if poly.contains(p):\n",
    "                points.append([x, y])\n",
    "            x += dx\n",
    "        y += dy\n",
    "        j += 1\n",
    "\n",
    "    return np.array(points)\n",
    "\n",
    "def delaunay_triangulation_within_polygon(points, polygon):\n",
    "    \"\"\"\n",
    "    Generates a Delaunay triangulation of a set of points that lie within a given polygon.\n",
    "\n",
    "    Args:\n",
    "        points: A list of (x, y) coordinate tuples or a NumPy array of shape (n, 2) representing the points.\n",
    "        polygon: A {Link: Shapely Polygon https://shapely.readthedocs.io/en/stable/manual.html#polygon} object representing the polygon.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "        - A NumPy array of shape (n, 2) representing the coordinates of the vertices of the triangulation.\n",
    "        - A NumPy array of shape (m, 3) representing the indices of the vertices that form each triangle.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create Delaunay triangulation\n",
    "    delaunay = Delaunay(points)\n",
    "\n",
    "    # Filter triangles that fall outside the polygon\n",
    "    triangles_within_polygon = []\n",
    "    for triangle_indices in delaunay.simplices:\n",
    "        triangle_points = points[triangle_indices]\n",
    "        triangle_polygon = Polygon(triangle_points)\n",
    "\n",
    "        if triangle_polygon.within(polygon):\n",
    "            triangles_within_polygon.append(triangle_indices)\n",
    "\n",
    "    # Return the filtered triangles\n",
    "    return points, np.array(triangles_within_polygon)\n",
    "\n",
    "def shortest_distance_to_polygon(point_coords, polygon_coords):\n",
    "    \"\"\"\n",
    "    Calculates the shortest distance from a point to a polygon outline.\n",
    "\n",
    "    Args:\n",
    "        point_coords (tuple): Coordinates of the point (x, y).\n",
    "        polygon_coords (list): List of coordinate tuples defining the polygon's vertices.\n",
    "\n",
    "    Returns:\n",
    "        float: The shortest distance from the point to the polygon outline.\n",
    "    \"\"\"\n",
    "    point = Point(point_coords)\n",
    "    polygon = Polygon(polygon_coords)\n",
    "\n",
    "    # Get the boundary (outline) of the polygon as a LinearRing\n",
    "    polygon_boundary = polygon.boundary\n",
    "\n",
    "    # Find the nearest point on the polygon boundary to the given point\n",
    "    nearest_point = nearest_points(point, polygon_boundary)[1]\n",
    "\n",
    "    # Calculate the distance between the point and the nearest point on the boundary\n",
    "    distance = point.distance(nearest_point)\n",
    "\n",
    "    return distance\n",
    "\n",
    "def rotate_points(xvals, yvals, degrees):\n",
    "    \"\"\"\"\n",
    "    define a function to rotate 2D x and y coordinate points around the origin\n",
    "    inputs: x and y vals (can take pandas dataframe columns) and the degrees (positive, anticlockwise) to rotate\n",
    "    outputs: rotated and y vals\n",
    "    \"\"\"\n",
    "    angle_to_move = 90-degrees\n",
    "    rads = np.deg2rad(angle_to_move)\n",
    "    \n",
    "    new_xvals = xvals*np.cos(rads)-yvals*np.sin(rads)\n",
    "    new_yvals = xvals*np.sin(rads)+yvals*np.cos(rads)\n",
    "    \n",
    "    return new_xvals, new_yvals\n",
    "\n",
    "def preserve_area(vertices_2d, faces, z_raw):\n",
    "    \"\"\"\n",
    "    Given an array of 2D vertices, indices of triangular faces, and z values, warp triangles into z axis while preserving area\n",
    "\n",
    "    Inputs\n",
    "    vertices_2d: array of 2D points\n",
    "    faces: indices of triangle faces\n",
    "    z_raw: z axis values into 3D plane\n",
    "\n",
    "    Outputs\n",
    "    z_adjusted: adjusted z values\n",
    "    \"\"\"\n",
    "    \n",
    "    vertices_3d = np.hstack([vertices_2d, z_raw[:, np.newaxis]])\n",
    "    z_adjusted = z_raw.copy()\n",
    "\n",
    "    for tri in faces:\n",
    "        i0, i1, i2 = tri\n",
    "        p0, p1, p2 = vertices_2d[[i0, i1, i2]]\n",
    "        a_2d = triangle_area_2d(p0, p1, p2)\n",
    "\n",
    "        p0_3d = np.array([*p0, z_adjusted[i0]])\n",
    "        p1_3d = np.array([*p1, z_adjusted[i1]])\n",
    "        p2_3d = np.array([*p2, z_adjusted[i2]])\n",
    "        a_3d = triangle_area_3d(p0_3d, p1_3d, p2_3d)\n",
    "\n",
    "        if a_3d == 0 or a_2d == 0:\n",
    "            continue  # skip degenerate triangles\n",
    "\n",
    "        scale = np.sqrt(a_2d / a_3d)\n",
    "\n",
    "        # Scale the Z-values locally to match the area\n",
    "        centroid_z = (z_adjusted[i0] + z_adjusted[i1] + z_adjusted[i2]) / 3.0\n",
    "        for i in [i0, i1, i2]:\n",
    "            deviation = z_adjusted[i] - centroid_z\n",
    "            z_adjusted[i] = centroid_z + deviation * scale\n",
    "\n",
    "    return z_adjusted\n",
    "\n",
    "def triangle_area_2d(p0, p1, p2):\n",
    "    return 0.5 * np.abs((p1[0] - p0[0]) * (p2[1] - p0[1]) -\n",
    "                        (p2[0] - p0[0]) * (p1[1] - p0[1]))\n",
    "\n",
    "def triangle_area_3d(p0, p1, p2):\n",
    "    v1 = p1 - p0\n",
    "    v2 = p2 - p0\n",
    "    return 0.5 * np.linalg.norm(np.cross(v1, v2))\n",
    "\n",
    "def sample_hex_grid(scaled_lfs,grid_density):\n",
    "    \"\"\"\n",
    "    For a 2D outline, sample approximately n points in a regular hexagon pattern within\n",
    "\n",
    "    Inputs\n",
    "    scaled_lfs: a 3D array of 2D leaf outlines across the leaf series\n",
    "    grid_density: the number of points to sample in a hexagonal grid within the leaf\n",
    "\n",
    "    Outputs\n",
    "    pts: a list of arrays for each leaf of the sampled hexagonal grid\n",
    "    tris: a list of arrays for each leaf of the pts indices that form triangular faces\n",
    "    \"\"\"\n",
    "\n",
    "    pts = [] # store each array of hex points for the leaves\n",
    "    tris = [] # store each array of face triangles for the leave\n",
    "    for i in range(len(scaled_lfs)):\n",
    "        hex_pts = hexagonal_points_for_n(scaled_lfs[i], grid_density) # calculate grid of hex points\n",
    "        verts, faces = delaunay_triangulation_within_polygon(hex_pts, Polygon(scaled_lfs[i])) # calculate Delauney triangulation\n",
    "        pts.append(verts) # save triangle points\n",
    "        tris.append(faces) # save triangle faces\n",
    "\n",
    "    return pts, tris\n",
    "\n",
    "def lift_points_radially(points_3d, angle_degrees):\n",
    "    \"\"\"\n",
    "    Rotates each point around the axis perpendicular to its (x, y) vector,\n",
    "    lifting it into the Z direction by the given angle.\n",
    "    Points at the origin remain unchanged.\n",
    "\n",
    "    Parameters:\n",
    "        points_3d (np.ndarray): Nx3 array of points (x, y, z)\n",
    "        angle_degrees (float): Angle in degrees to lift into Z\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Nx3 array of rotated 3D points\n",
    "    \"\"\"\n",
    "    angle_radians = np.deg2rad(angle_degrees)\n",
    "    lifted_points = []\n",
    "\n",
    "    for x, y, z in points_3d:\n",
    "        if np.isclose(x, 0) and np.isclose(y, 0):\n",
    "            # Leave origin fixed\n",
    "            lifted_points.append([0, 0, z])\n",
    "            continue\n",
    "\n",
    "        # Get direction vector in XY plane from origin to point\n",
    "        v_xy = np.array([x, y, 0])\n",
    "        norm_xy = np.linalg.norm(v_xy)\n",
    "        v_xy_unit = v_xy / norm_xy\n",
    "\n",
    "        # Axis of rotation is perpendicular to (x, y, 0) in the XY plane\n",
    "        # Cross with Z to get rotation axis\n",
    "        axis = np.cross(v_xy_unit, [0, 0, 1])  # This is the rotation axis\n",
    "        axis = axis / np.linalg.norm(axis)\n",
    "\n",
    "        # Rodrigues' rotation formula\n",
    "        v = np.array([x, y, z])\n",
    "        k = axis\n",
    "        cos_theta = np.cos(angle_radians)\n",
    "        sin_theta = np.sin(angle_radians)\n",
    "\n",
    "        v_rot = (v * cos_theta +\n",
    "                 np.cross(k, v) * sin_theta +\n",
    "                 k * np.dot(k, v) * (1 - cos_theta))\n",
    "\n",
    "        lifted_points.append(v_rot)\n",
    "\n",
    "    return np.array(lifted_points)\n",
    "\n",
    "def generate_3D_points(pts,scaled_lfs,leaf_curve,leaf_mid,leaf_tip,leaf_curl,phyllo_ang,warp,angle_min,angle_max, n):\n",
    "    \"\"\"\n",
    "    Given 2D grid points, use functions to calculate leaf curvature and curl, rotation, and elevation\n",
    "\n",
    "    Inputs\n",
    "    pts: a list of arrays of 2D hexagonal grid points\n",
    "    scaled_lfs: an array of leaf shapes scaled by length with base at origin\n",
    "    leaf_curve, leaf_mid, leaf_tip, leaf_curl: parameters for specifying 3D leaf surface\n",
    "    phyllo_ang: angle to rotate leaf for each successive node\n",
    "    warp: True/False, whether to preserve triangle surface area when moving into z axis\n",
    "    angle_min, angle_max: parameters to calculate leaf elevation angles\n",
    "    n: the number of leaves in the leaf series\n",
    "\n",
    "    Outputs\n",
    "    pts_3D: a list of x, y, z vertices for leaf shape\n",
    "    \"\"\"\n",
    "\n",
    "    pts_3D = [] # list of x,y,z vertices\n",
    "    \n",
    "    for i in range(len(pts)): # for each leaf in the list of arrays of points and triangle faces\n",
    "    \n",
    "        # LEAF CURVATURE\n",
    "        # get distances of each grid point to polygon boundary\n",
    "        dists=[]\n",
    "        for j in range(len(pts[i])):\n",
    "            dists.append(shortest_distance_to_polygon((pts[i][j,0],pts[i][j,1]),scaled_lfs[i]))\n",
    "        scaled_lf_curve = np.array(dists)*leaf_curve # get scaled leaf curvature\n",
    "        \n",
    "        # LEAF CURL\n",
    "        # calculate leaf curl from distance to base\n",
    "        coeffs = np.polyfit(x=[0,0.5,1], y=[0,leaf_mid,leaf_tip], deg=2) # calculate coefficients\n",
    "        func = np.poly1d(coeffs) # calculate 2D polynomial function\n",
    "        \n",
    "        lf_curl_vals = func(pts[i][:,1])*leaf_curl*np.max(pts[i][:,1]) # calculate leaf lengths relative to 1\n",
    "        \n",
    "        # OVERALL Z SURFACE CALCULATION\n",
    "        lf_surf_vals = scaled_lf_curve+lf_curl_vals # calculate overall curvature\n",
    "        lf_surf_lf = np.column_stack((pts[i], lf_surf_vals)) # combine x, y, and z vals\n",
    "        \n",
    "        # translate the z axis to the origin\n",
    "        lf_surf_lf[:,2] = lf_surf_lf[:,2] - np.mean(lf_surf_lf[:,2][lf_surf_lf[:,1]==np.min(lf_surf_lf[:,1])] )\n",
    "        \n",
    "        # ROTATE LEAF\n",
    "        rot_x, rot_y = rotate_points(lf_surf_lf[:,0],lf_surf_lf[:,1], phyllo_ang*i)\n",
    "        lf_surf_lf[:,0:2] = np.column_stack((rot_x, rot_y))\n",
    "        \n",
    "        if warp==True:\n",
    "        \n",
    "            # Warp Dlauney triangulation into 3D\n",
    "            # get surface values of leaf\n",
    "            z_raw = lf_surf_lf[:,2]\n",
    "            \n",
    "            # get the x and y coordinate values\n",
    "            vertices_2d = lf_surf_lf[:,0:2]\n",
    "            \n",
    "            # Area-preserving adjustment\n",
    "            z_warped = preserve_area(vertices_2d, tris[i], z_raw)\n",
    "            \n",
    "            # Now vertices_3d = [x, y, z_warped]\n",
    "            vertices_3d = np.hstack([vertices_2d, z_warped[:, np.newaxis]])\n",
    "        \n",
    "        else:\n",
    "            vertices_3d = lf_surf_lf\n",
    "        \n",
    "        # Elevate the leaves\n",
    "        # elevate the points\n",
    "        angs = np.linspace(angle_min, angle_max, n)\n",
    "        elv_pts = lift_points_radially(vertices_3d, angs[i])\n",
    "        \n",
    "        pts_3D.append(elv_pts) # append points to list\n",
    "\n",
    "    return pts_3D\n",
    "\n",
    "def fibonacci_sphere(samples=1000):\n",
    "    \"\"\"\n",
    "    For the number of samples, calculate a hemisphere of points arranged in an equally spaced Fibonacci pattern\n",
    "\n",
    "    Inputs:\n",
    "    samples: the number of points to calculate for a sphere (will return half as much as a hemisphere\n",
    "\n",
    "    Outputs:\n",
    "    points: a list of points sampled from the hemisphere\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    phi = math.pi * (math.sqrt(5.) - 1.)  # golden angle in radians\n",
    "    for i in range(samples):\n",
    "        y = 1 - (i / float(samples - 1)) * 2  # y goes from 1 to -1\n",
    "        radius = math.sqrt(1 - y * y)  # radius at y\n",
    "        theta = phi * i  # golden angle increment\n",
    "        x = math.cos(theta) * radius\n",
    "        z = math.sin(theta) * radius\n",
    "        points.append((x, y, z))\n",
    "    return points\n",
    "\n",
    "def ray_casting(pts_3D, tris, n_origins, radius, n_sample):\n",
    "    \"\"\"\n",
    "    For a 3D model of points and triangular faces, perform a ray casting experiment to test for proportion of intercepted rays\n",
    "\n",
    "    Inputs\n",
    "    pts_3D: a list of 3D arrays of leaf surfaces in the series\n",
    "    tris: a list of arrays of vertices of triangular faces for each leaf\n",
    "    n_origins: the number of Fibonacci sphere points to sample for ray origins\n",
    "    radius: the radius of the sphere\n",
    "    n_sample: the number of rays to subsample\n",
    "\n",
    "    Outputs\n",
    "    proportion_correct: the proportion of rays that intercepted their intended leaf surface face\n",
    "    total_area: the total surface area of the mesh\n",
    "    \"\"\"\n",
    "\n",
    "    #####\n",
    "    # NORMALIZE RADIUS TO FARTHEST POINT FROM ORIGIN\n",
    "    #####\n",
    "    \n",
    "    dists = []\n",
    "    for i in range(len(pts_3D)):\n",
    "        for j in range(len(pts_3D[i])):\n",
    "            dists.append(np.sqrt( ((pts_3D[i][j][0])**2 +\n",
    "                                   (pts_3D[i][j][1])**2 +\n",
    "                                   (pts_3D[i][j][2])**2)\n",
    "                                ))\n",
    "    \n",
    "    max_dist = np.max(dists) # get the max radius to normalize by\n",
    "    \n",
    "    norm_pts_3D = [] # normalize 3D points\n",
    "    for i in range(len(pts_3D)):\n",
    "        norm_pts_3D.append(pts_3D[i]/max_dist)\n",
    "    \n",
    "    pts_3D = norm_pts_3D\n",
    "    \n",
    "    #####\n",
    "    # CREATE MESH\n",
    "    #####\n",
    "    \n",
    "    # create mesh of first leaf\n",
    "    mesh = trimesh.Trimesh(vertices=pts_3D[0], faces=tris[0])\n",
    "    \n",
    "    # concatenate the meshes of other leaves\n",
    "    for i in range(1, len(pts_3D)):\n",
    "        new_mesh = trimesh.Trimesh(vertices=pts_3D[i], faces=tris[i])\n",
    "        mesh = trimesh.util.concatenate(mesh, new_mesh)\n",
    "    \n",
    "    #####\n",
    "    # CALCULATE RAY ORIGINS\n",
    "    #####\n",
    "    \n",
    "    fibo_pts = fibonacci_sphere(samples = n_origins) # calculate points\n",
    "    fibo_arr = np.array(fibo_pts) # turn tuples into array\n",
    "    ray_origins = fibo_arr[fibo_arr[:,2]>0]*radius # select points in the positive hemisphere\n",
    "    \n",
    "    #####\n",
    "    # PERFORM RAY CASTING\n",
    "    #####\n",
    "    \n",
    "    # --- Get face centers of mesh ---\n",
    "    face_centers = mesh.triangles_center  # shape (M, 3)\n",
    "    n_faces = len(face_centers)\n",
    "    n_origins = len(ray_origins)\n",
    "    \n",
    "    # --- Build ray origins and directions ---\n",
    "    ray_origins_batch = []\n",
    "    ray_directions_batch = []\n",
    "    intended_face_indices = []\n",
    "    \n",
    "    for origin_idx, origin in enumerate(ray_origins):\n",
    "        dirs = face_centers - origin  # (n_faces, 3)\n",
    "        dirs /= np.linalg.norm(dirs, axis=1, keepdims=True)\n",
    "        \n",
    "        ray_origins_batch.append(np.repeat(origin[np.newaxis, :], n_faces, axis=0))\n",
    "        ray_directions_batch.append(dirs)\n",
    "        intended_face_indices.append(np.arange(n_faces))  # face indices\n",
    "    \n",
    "    # Flatten arrays\n",
    "    ray_origins_batch = np.vstack(ray_origins_batch)  # shape (N, 3)\n",
    "    ray_directions_batch = np.vstack(ray_directions_batch)  # shape (N, 3)\n",
    "    intended_face_indices = np.tile(np.arange(n_faces), n_origins)  # shape (N,)\n",
    "    \n",
    "    # --- Subsample rays ---\n",
    "    N_total = len(ray_origins_batch)\n",
    "    n_sample = min(n_sample, N_total)\n",
    "    sample_idx = np.random.choice(N_total, size=n_sample, replace=False)\n",
    "    \n",
    "    ray_origins_sub = ray_origins_batch[sample_idx]\n",
    "    ray_directions_sub = ray_directions_batch[sample_idx]\n",
    "    intended_faces_sub = intended_face_indices[sample_idx]\n",
    "    \n",
    "    # --- Cast rays ---\n",
    "    locations, ray_index, tri_index = mesh.ray.intersects_location(\n",
    "        ray_origins_sub, \n",
    "        ray_directions_sub, \n",
    "        multiple_hits=False\n",
    "    )\n",
    "    \n",
    "    # --- Determine interception correctness ---\n",
    "    hit_intended = tri_index == intended_faces_sub[ray_index]\n",
    "    proportion_correct = np.sum(hit_intended) / len(ray_index)\n",
    "    proportion_incorrect = 1 - proportion_correct\n",
    "    total_area = mesh.area\n",
    "\n",
    "    return proportion_correct, total_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a354f07-84ad-41cc-a04a-13e65c0719a7",
   "metadata": {},
   "source": [
    "# 1. Set & Save parameters values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1127fdd5-c8b6-4ba8-aeb7-3520db9243c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of parameter set\n",
    "parameter_name = \"nahuatlleaftest\"\n",
    "\n",
    "# morphospace and PC values to synthesize leaf shape\n",
    "morphospace_file = \"nahuatl_morphospace_may_10_2025.pkl\" # PCA model file, .pkl file\n",
    "PC_val_file = \"nahuatl_PCs_may_10_2025.npy\" # empirical PCA values from the PCA, .npy file\n",
    "\n",
    "# select two PC axes to sythesize leaves from\n",
    "PCa = 0 # index position of first PC (index 0 = PC1)\n",
    "PCb = 4 # index position of second PC (index 0 = PC1)\n",
    "\n",
    "# set value for approximately how many points within each polygon leaf to place\n",
    "grid_density = 100 # number of points to sample within leaf\n",
    "\n",
    "# select the range of leaf numbers to uniformly sample from\n",
    "low_lf_num = 3 # inclusive\n",
    "high_lf_num = 10 # up to, not including\n",
    "\n",
    "# set relative height of first leaf in series\n",
    "low_juv_len = 0.2 # inclusive\n",
    "high_juv_len = 1 # not including\n",
    "\n",
    "# set height of last leaf relative to one\n",
    "low_adult_len = 0.2 # inclusive\n",
    "high_adult_len = 1 # not including\n",
    "\n",
    "# set maximum scaling values for leaf curvature and leaf curling\n",
    "lf_curve = 0.8 # max scaling of leaf curvature (the interior of the leaf)\n",
    "lf_curl = 0.8 # max scaling of leaf curl (across length of leaf)\n",
    "\n",
    "# set maximum displacement at leaf tip (y value), relative to -1, 1\n",
    "max_down_curl = -1 \n",
    "max_up_curl = 1\n",
    "\n",
    "# set minimum and maximum limits of leaf angles\n",
    "ang_min_limit = 10 # max possible min angle\n",
    "ang_max_limit = 90 # max possible angle\n",
    "\n",
    "# set phyllotaxy angle option (in degrees)\n",
    "# select from options below:\n",
    "# 0 = [-137.5077640500378546463487,137.5077640500378546463487]\n",
    "# 1 = [-137.5077640500378546463487,137.5077640500378546463487,90,180]\n",
    "# 2 = [-137.5077640500378546463487,137.5077640500378546463487,90,180,<random -360 to +360>]\n",
    "# 3 = [<random -360 to +360>]\n",
    "phyllo_option = 2\n",
    "\n",
    "# list of parameter names\n",
    "param_name_list = [\n",
    "    \"parameter_name\", \n",
    "    \"morphospace_file\", \n",
    "    \"PC_val_file\",\n",
    "    \"PCa\", \n",
    "    \"PCb\",\n",
    "    \"grid_density\",\n",
    "    \"low_lf_num\",\n",
    "    \"high_lf_num\",\n",
    "    \"low_juv_len\",\n",
    "    \"high_juv_len\",\n",
    "    \"low_adult_len\",\n",
    "    \"high_adult_len\",\n",
    "    \"lf_curve\",\n",
    "    \"lf_curl\",\n",
    "    \"max_down_curl\",\n",
    "    \"max_up_curl\",\n",
    "    \"ang_min_limit\",\n",
    "    \"ang_max_limit\",\n",
    "    \"phyllo_option\"\n",
    "]\n",
    "\n",
    "# list of parameter values\n",
    "param_val_list = [\n",
    "    parameter_name, \n",
    "    morphospace_file, \n",
    "    PC_val_file,\n",
    "    PCa, \n",
    "    PCb,\n",
    "    grid_density,\n",
    "    low_lf_num,\n",
    "    high_lf_num,\n",
    "    low_juv_len,\n",
    "    high_juv_len,\n",
    "    low_adult_len,\n",
    "    high_adult_len,\n",
    "    lf_curve,\n",
    "    lf_curl,\n",
    "    max_down_curl,\n",
    "    max_up_curl,\n",
    "    ang_min_limit,\n",
    "    ang_max_limit,\n",
    "    phyllo_option\n",
    "]\n",
    "\n",
    "# save the parameters to file\n",
    "save_params(keys=param_name_list, values=param_val_list, path = \"./\" + parameter_name + \"_params.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e68a1b-507f-405b-a3ac-3a349482fd1c",
   "metadata": {},
   "source": [
    "# 2. Calculate & Save model values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d11612d-49a8-4375-8b22-5ef3131f16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of desired model values\n",
    "n_models = 1000\n",
    "\n",
    "# specify the folder to save model values\n",
    "model_values_path = \"model_values\"\n",
    "\n",
    "# name of parameter set\n",
    "parameter_name = \"nahuatlleaftest\"\n",
    "\n",
    "# read in parameter file and set parameter values\n",
    "param_path = \"./\" + parameter_name + \"_params.csv\"\n",
    "param_var_dict = set_params(param_path)\n",
    "\n",
    "# save model values as csv files to folder for n number of models\n",
    "save_model_values(param_var_dict, model_values_path, n_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fd66d-c68f-4b94-9a5e-cf60c9bfe08e",
   "metadata": {},
   "source": [
    "# 3. Generate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e00868f-cc9d-4c0b-a313-a83921f43c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify path \n",
    "model_values_path = \"model_values\"\n",
    "\n",
    "# get file names of model values\n",
    "file_names = os.listdir(model_values_path) \n",
    "\n",
    "# make sure no hidden files\n",
    "for i in range(len(file_names)): \n",
    "    if file_names[i][0]==\".\":\n",
    "        file_names.remove(i)\n",
    "\n",
    "# specify necessary variables\n",
    "leaf_series_path = \"leaf_series\" # folder name to save leaf shape results\n",
    "n_save = 5 # number of comparable leaves in the series for leaf shapes saved\n",
    "warp = True # should z values be warped to preserve triangle surface areas\n",
    "n_origins = 1000 # number of points on Fibonacci sphere to sample for ray origins\n",
    "radius = 2 # radius of Fibonacci sphere\n",
    "n_sample = 1000 # number of rays to subsample\n",
    "results_path = \"results\" # folder name to save ray casting results\n",
    "\n",
    "if not os.path.exists(results_path): # check if the folder exists\n",
    "    # create the folder if it doesn't exist\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "for file in file_names:\n",
    "\n",
    "    # retrieve parameter file name from model values string\n",
    "    # read in and set parameter values\n",
    "    param_var_dict = set_params(file[file.index(\"_\")+1:-4]+\"_params.csv\")\n",
    "    \n",
    "    # read in and set model values\n",
    "    model_var_dict = set_model_values(model_values_path+\"/\"+file)\n",
    "    \n",
    "    # read in pca morphospace and PC values\n",
    "    pca, PCs = read_in_morphospace(morphospace_file, PC_val_file)\n",
    "    \n",
    "    # generate a leaf series\n",
    "    leaf_series = generate_leaf_series(n,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca)\n",
    "    \n",
    "    # check if any leaf in the series is self-intersecting\n",
    "    if any_leaf_self_intersecting(leaf_series): # if a self-intersecting leaf, continue\n",
    "        continue\n",
    "    \n",
    "    # translate leaf base to origin\n",
    "    trans_lfs = translate_base_to_origin(leaf_series)\n",
    "    \n",
    "    # scale the lengths of the leaves in the series\n",
    "    scaled_lfs = scale_leaf_series(node_max, juv_len, adult_len, trans_lfs, n)\n",
    "    \n",
    "    # save leaf shapes in series of a comparable number, n_save\n",
    "    save_leaf_series(file,leaf_series_path,n_save,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca,node_max,juv_len,adult_len)\n",
    "    \n",
    "    # sample hexagonal grid points and indices of triangular faces within each leaf\n",
    "    pts, tris = sample_hex_grid(scaled_lfs,grid_density)\n",
    "    \n",
    "    # create 3D leaf surface\n",
    "    pts_3D = generate_3D_points(pts,scaled_lfs,leaf_curve,leaf_mid,leaf_tip,leaf_curl,phyllo_ang,warp,angle_min,angle_max, n)\n",
    "    \n",
    "    # perform ray casting experiment\n",
    "    proportion_correct, total_area = ray_casting(pts_3D, tris, n_origins, radius, n_sample)\n",
    "    \n",
    "    # save results\n",
    "    np.save(results_path+'/r'+file[1:-4]+\".npy\", np.array([proportion_correct, total_area]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb97e8d3-2903-4ac7-9489-21d1993ccc54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b6c9a-36a1-40a6-b453-21bc9871c983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d779858-9532-49ed-a48c-862e25b8f9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4f17b-0afd-40fc-96bd-ccaabac6fd22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70097aad-7ec6-48c4-944c-eaf9e7501918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98204bb9-b466-4f6d-a1fd-6ed52f9a9dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adab8b-216f-4fa8-871b-10bd8ad95cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a627072-ed69-4546-8c6a-6ae92e06f672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0b1c3-e55e-4b6e-9418-3aea7c3c88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57b939-f473-49e2-801f-98d4ab678221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c5f253-e7ac-4d01-839d-5582db558f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec94be9-b813-4875-a9cc-500d5816b229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af32950b-cc7e-47da-956a-d9efd54ef5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c2ee8-5aa8-4577-84dd-a75b7bf43631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7b56b19b-df33-406d-9025-5baf62a5559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# specify path \n",
    "model_values_path = \"model_values\"\n",
    "\n",
    "# get file names of model values\n",
    "file_names = os.listdir(model_values_path) \n",
    "\n",
    "# make sure no hidden files\n",
    "for i in range(len(file_names)): \n",
    "    if file_names[i][0]==\".\":\n",
    "        file_names.remove(i)\n",
    "\n",
    "# specify necessary variables\n",
    "leaf_series_path = \"leaf_series\" # folder name to save leaf shape results\n",
    "n_save = 5 # number of comparable leaves in the series for leaf shapes saved\n",
    "warp = True # should z values be warped to preserve triangle surface areas\n",
    "n_origins = 1000 # number of points on Fibonacci sphere to sample for ray origins\n",
    "radius = 2 # radius of Fibonacci sphere\n",
    "n_sample = 1000 # number of rays to subsample\n",
    "results_path = \"results\" # folder name to save ray casting results\n",
    "\n",
    "if not os.path.exists(results_path): # check if the folder exists\n",
    "    # create the folder if it doesn't exist\n",
    "    os.makedirs(results_path)\n",
    "\n",
    "##################################\n",
    "# select a random model value file\n",
    "file = np.random.choice(file_names)\n",
    "##################################\n",
    "\n",
    "# retrieve parameter file name from model values string\n",
    "# read in and set parameter values\n",
    "param_var_dict = set_params(file[file.index(\"_\")+1:-4]+\"_params.csv\")\n",
    "\n",
    "# read in and set model values\n",
    "model_var_dict = set_model_values(model_values_path+\"/\"+file)\n",
    "\n",
    "# read in pca morphospace and PC values\n",
    "pca, PCs = read_in_morphospace(morphospace_file, PC_val_file)\n",
    "\n",
    "# generate a leaf series\n",
    "leaf_series = generate_leaf_series(n,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca)\n",
    "\n",
    "# check if any leaf in the series is self-intersecting\n",
    "# (later, continue in loop of model values if True)\n",
    "print(any_leaf_self_intersecting(leaf_series))\n",
    "\n",
    "# translate leaf base to origin\n",
    "trans_lfs = translate_base_to_origin(leaf_series)\n",
    "\n",
    "# scale the lengths of the leaves in the series\n",
    "scaled_lfs = scale_leaf_series(node_max, juv_len, adult_len, trans_lfs, n)\n",
    "\n",
    "# save leaf shapes in series of a comparable number, n_save\n",
    "save_leaf_series(file,leaf_series_path,n_save,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca,node_max,juv_len,adult_len)\n",
    "\n",
    "# sample hexagonal grid points and indices of triangular faces within each leaf\n",
    "pts, tris = sample_hex_grid(scaled_lfs,grid_density)\n",
    "\n",
    "# create 3D leaf surface\n",
    "pts_3D = generate_3D_points(pts,scaled_lfs,leaf_curve,leaf_mid,leaf_tip,leaf_curl,phyllo_ang,warp,angle_min,angle_max, n)\n",
    "\n",
    "# perform ray casting experiment\n",
    "proportion_correct, total_area = ray_casting(pts_3D, tris, n_origins, radius, n_sample)\n",
    "\n",
    "# save results\n",
    "np.save(results_path+'/r'+file[1:-4]+\".npy\", np.array([proportion_correct, total_area]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f5dfa3-1bea-497a-b6b7-6229c49eb090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29e01e-6575-4fc2-ad3e-f7a26ab323fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07368164-9df8-40c4-83f3-7c2de72804f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514d101f-6d3b-446a-8540-4f27da9c6ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b3b4c8-dd57-42a5-afc5-9688102f3068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e5236e-72ca-4065-b155-ba47643d88d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bc31e-d833-47ec-bef8-3f5a0b05b5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a240d276-134f-4616-a14c-2d940a127015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3edb54e-0ef9-4582-b0aa-031f81debf02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cd89828-67c2-4e25-8d31-e6baff820848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m436_nahuatlleaftest.csv\n",
      "m222_nahuatlleaftest.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 101 is out of bounds for axis 0 with size 92",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_names: \u001b[38;5;66;03m# for each saved model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m---> 27\u001b[0m     overall_function(file,leaf_series_path,n_save,n_origins,radius,n_sample,results_path,warp)\n",
      "Cell \u001b[0;32mIn[45], line 34\u001b[0m, in \u001b[0;36moverall_function\u001b[0;34m(file, leaf_series_path, n_save, n_origins, radius, n_sample, results_path, warp)\u001b[0m\n\u001b[1;32m     31\u001b[0m pts, tris \u001b[38;5;241m=\u001b[39m sample_hex_grid(scaled_lfs,grid_density)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# create 3D leaf surface\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m pts_3D \u001b[38;5;241m=\u001b[39m generate_3D_points(pts,scaled_lfs,leaf_curve,leaf_mid,leaf_tip,leaf_curl,phyllo_ang,warp,angle_min,angle_max, n)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# perform ray casting experiment\u001b[39;00m\n\u001b[1;32m     37\u001b[0m proportion_correct, total_area \u001b[38;5;241m=\u001b[39m ray_casting(pts_3D, tris, n_origins, radius, n_sample)\n",
      "Cell \u001b[0;32mIn[41], line 888\u001b[0m, in \u001b[0;36mgenerate_3D_points\u001b[0;34m(pts, scaled_lfs, leaf_curve, leaf_mid, leaf_tip, leaf_curl, phyllo_ang, warp, angle_min, angle_max, n)\u001b[0m\n\u001b[1;32m    885\u001b[0m vertices_2d \u001b[38;5;241m=\u001b[39m lf_surf_lf[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    887\u001b[0m \u001b[38;5;66;03m# Area-preserving adjustment\u001b[39;00m\n\u001b[0;32m--> 888\u001b[0m z_warped \u001b[38;5;241m=\u001b[39m preserve_area(vertices_2d, tris[i], z_raw)\n\u001b[1;32m    890\u001b[0m \u001b[38;5;66;03m# Now vertices_3d = [x, y, z_warped]\u001b[39;00m\n\u001b[1;32m    891\u001b[0m vertices_3d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([vertices_2d, z_warped[:, np\u001b[38;5;241m.\u001b[39mnewaxis]])\n",
      "Cell \u001b[0;32mIn[41], line 733\u001b[0m, in \u001b[0;36mpreserve_area\u001b[0;34m(vertices_2d, faces, z_raw)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tri \u001b[38;5;129;01min\u001b[39;00m faces:\n\u001b[1;32m    732\u001b[0m     i0, i1, i2 \u001b[38;5;241m=\u001b[39m tri\n\u001b[0;32m--> 733\u001b[0m     p0, p1, p2 \u001b[38;5;241m=\u001b[39m vertices_2d[[i0, i1, i2]]\n\u001b[1;32m    734\u001b[0m     a_2d \u001b[38;5;241m=\u001b[39m triangle_area_2d(p0, p1, p2)\n\u001b[1;32m    736\u001b[0m     p0_3d \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m*\u001b[39mp0, z_adjusted[i0]])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 101 is out of bounds for axis 0 with size 92"
     ]
    }
   ],
   "source": [
    "# specify path \n",
    "model_values_path = \"model_values\"\n",
    "\n",
    "# get file names of model values\n",
    "file_names = os.listdir(model_values_path) \n",
    "\n",
    "# make sure no hidden files\n",
    "for i in range(len(file_names)): \n",
    "    if file_names[i][0]==\".\":\n",
    "        file_names.remove(i)\n",
    "\n",
    "\n",
    "#for file in file_names: # for each saved model\n",
    "#    if ray_casting(radius,n_sample,results_path,file,leaf_series_path,n_save,warp,n_origins,):\n",
    "#        continue\n",
    "\n",
    "for file in file_names: # for each saved model\n",
    "    print(file)\n",
    "    overall_function(file,leaf_series_path,n_save,n_origins,radius,n_sample,results_path,warp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69688d7-68a3-477d-8362-de020d6d19c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e3e0c0-b205-43f9-9a9b-b339df7b3490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f399a5-828d-42c7-bc58-1d063e348f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "301aea09-3462-418c-aaf4-2ab769df8a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_function(file,leaf_series_path,n_save,n_origins,radius,n_sample,results_path,warp):\n",
    "    \n",
    "    # retrieve parameter file name from model values string\n",
    "    # read in and set parameter values\n",
    "    param_var_dict = set_params(file[file.index(\"_\")+1:-4]+\"_params.csv\")\n",
    "    \n",
    "    # read in and set model values\n",
    "    model_var_dict = set_model_values(model_values_path+\"/\"+file)\n",
    "    \n",
    "    # read in pca morphospace and PC values\n",
    "    pca, PCs = read_in_morphospace(morphospace_file, PC_val_file)\n",
    "    \n",
    "    # generate a leaf series\n",
    "    leaf_series = generate_leaf_series(n,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca)\n",
    "    \n",
    "    # check if any leaf in the series is self-intersecting\n",
    "    # if True, then indicate to the loop to continue on to next sample\n",
    "    if any_leaf_self_intersecting(leaf_series):\n",
    "        return True\n",
    "    \n",
    "    # translate leaf base to origin\n",
    "    trans_lfs = translate_base_to_origin(leaf_series)\n",
    "    \n",
    "    # scale the lengths of the leaves in the series\n",
    "    scaled_lfs = scale_leaf_series(node_max, juv_len, adult_len, trans_lfs, n)\n",
    "    \n",
    "    # save leaf shapes in series of a comparable number, n_save\n",
    "    save_leaf_series(file,leaf_series_path,n_save,start_x,start_y,end_x,end_y,PCs,PCa,PCb,pca,node_max,juv_len,adult_len)\n",
    "    \n",
    "    # sample hexagonal grid points and indices of triangular faces within each leaf\n",
    "    pts, tris = sample_hex_grid(scaled_lfs,grid_density)\n",
    "    \n",
    "    # create 3D leaf surface\n",
    "    pts_3D = generate_3D_points(pts,scaled_lfs,leaf_curve,leaf_mid,leaf_tip,leaf_curl,phyllo_ang,warp,angle_min,angle_max, n)\n",
    "    \n",
    "    # perform ray casting experiment\n",
    "    proportion_correct, total_area = ray_casting(pts_3D, tris, n_origins, radius, n_sample)\n",
    "\n",
    "    if not os.path.exists(results_path): # check if the folder exists\n",
    "        # create the folder if it doesn't exist\n",
    "        os.makedirs(results_path)\n",
    "    \n",
    "    # save results\n",
    "    np.save(results_path+'/r'+file[1:-4]+\".npy\", np.array([proportion_correct, total_area]))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce43f326-a085-484f-bf40-4581448addf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
